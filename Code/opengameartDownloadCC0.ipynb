{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opengameart.org CC0 Image Download\n",
    "\n",
    "This notebook downloads and cleans data from opengameart.org."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Get Collection Links\n",
    "#### Step 2: Get File Links\n",
    "#### Step 3: Download Files\n",
    "#### Step 4: Copy and Rename Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, bs4, os, json, zipfile, io, cv2, numpy as np\n",
    "from statistics import mean\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from distutils.dir_util import copy_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_time_remaining(i, total, times, last_time, a='Page'):\n",
    "    \"\"\"\n",
    "    Calculates the time remaining on a function given time and iteration count.\n",
    "    Parameters:\n",
    "        i: iteration number\n",
    "        total: total iterations\n",
    "        times: list of run times\n",
    "        last_time: last datetime\n",
    "        a: things iterated over\n",
    "    Returns:\n",
    "        times, now\n",
    "    \"\"\"\n",
    "    now = datetime.now()\n",
    "    times.append((now-last_time).microseconds/1000000)\n",
    "    avg_time = round(mean(times), 2)\n",
    "    ETA = round(avg_time*(total-i))  \n",
    "    print(\"{}/{} {}(s) Scraped. Avg. Time: {}. Est. Remaining: {}\".format(i, total, a, avg_time, ETA), end='\\r')\n",
    "    return times, now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Get Collection Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(dim, pages=2):\n",
    "    \"\"\"\n",
    "    Gets every collection link from opengameart.org\n",
    "    parameters:\n",
    "        dim: dimension integer\n",
    "        pages: number of pages o scrape\n",
    "    Returns:\n",
    "        list of links\n",
    "    \"\"\"\n",
    "    times = []; last_time = datetime.now()\n",
    "    if 'data_1.json' not in os.listdir():\n",
    "        if dim == 2:\n",
    "            base = \"https://opengameart.org/art-search-advanced?keys=&title=&field_art_tags_tid_op=or&field_art_tags_tid=&name=&field_art_type_tid%5B%5D=9&field_art_licenses_tid%5B%5D=4&sort_by=count&sort_order=DESC&items_per_page=144&Collection=&page={}\"\n",
    "        if dim == 3:\n",
    "            base = \"https://opengameart.org/art-search-advanced?keys=&title=&field_art_tags_tid_op=or&field_art_tags_tid=&name=&field_art_type_tid%5B%5D=10&field_art_licenses_tid%5B%5D=4&sort_by=count&sort_order=DESC&items_per_page=144&Collection=&page={}\"\n",
    "        links_all = []\n",
    "        for page in list(range(pages)):\n",
    "            r = requests.get(base.format(str(page)))\n",
    "            if r.status_code==200:\n",
    "                soup = bs4.BeautifulSoup(r.content, 'lxml')\n",
    "                links = []\n",
    "                for s in soup.find_all('div', {'class':'field-item even'}):\n",
    "                    try:\n",
    "                        href = s.find('a')['href']\n",
    "                        if '/content' in href:\n",
    "                            links.append(href)\n",
    "                    except:\n",
    "                        pass\n",
    "                links_all+=links; links_all=list(set(links_all))\n",
    "            times, last_time = est_time_remaining(page+1, pages, times, last_time)\n",
    "    return links_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 Page(s) Scraped. Avg. Time: 0.58. Est. Remaining: 0\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_all = get_links(2)\n",
    "len(links_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get File Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_links(links_all):\n",
    "    \"\"\"For each collection, gets the links of the files to download\n",
    "    Parameters:\n",
    "        links_all: list of collection links\n",
    "    Returns:\n",
    "        list of file links\n",
    "    \"\"\"\n",
    "    files = []; i = 1\n",
    "    total = len(links_all); times = []; last_time=datetime.now()\n",
    "    for link in links_all:\n",
    "        base='https://opengameart.org'\n",
    "        try:\n",
    "            r=requests.get(base+link)\n",
    "            if r.status_code == 200:\n",
    "                soup = bs4.BeautifulSoup(r.content, 'lxml')\n",
    "                try:\n",
    "                    file_path = soup.find('span', {'class':'file'}).find('a')['href']\n",
    "                    files.append([link, file_path])\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    for div in soup.find('div', {'class':'group-right right-column'}).find('div', {'class':'field-items'}).find_all('div'):\n",
    "                        files.append([link,div.find('a')['href']])\n",
    "                except:\n",
    "                    pass\n",
    "        except:\n",
    "            pass\n",
    "        times, last_time = est_time_remaining(i, total, times, last_time); i+=1\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 Page(s) Scraped. Avg. Time: 0.54. Est. Remaining: 0\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_links = get_file_links(links_all[:3])\n",
    "len(file_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(files):\n",
    "    \"\"\"Downloads every file to the local directory (requires about 10gb storage for all collections)\n",
    "    Parameters:\n",
    "        files: list of files to download\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs('SpriteFiles')\n",
    "    except:\n",
    "        return \"Directory Exists\"\n",
    "    len(links_all); times = []; last_time=datetime.now()\n",
    "    i=1; l=len(files)\n",
    "    for file_pair in files:\n",
    "        if 'zip' in file_pair[-1]:\n",
    "            try:\n",
    "                os.makedirs('SpriteFiles/'+file_pair[0].split('/')[-1])\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                r = requests.get(file_pair[-1])\n",
    "                z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "                z.extractall('SpriteFiles/'+file_pair[0].split('/')[-1])\n",
    "            except:\n",
    "                print(file_pair[-1])\n",
    "                \n",
    "        if 'png' in file_pair[-1]:\n",
    "            try:\n",
    "                os.makedirs('SpriteFiles/'+file_pair[0].split('/')[-1])\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                r = requests.get(file_pair[-1], stream=True)\n",
    "                if r.status_code == 200:\n",
    "                    with open('SpriteFiles/'+file_pair[0].split('/')[-1]+'/test.png', 'wb') as f:\n",
    "                        for chunk in r:\n",
    "                            f.write(chunk)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            \n",
    "        times, last_time = est_time_remaining(i, l, times, last_time, a='Files'); i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/2 Files(s) Scraped. Avg. Time: 0.63. Est. Remaining: -1\r"
     ]
    }
   ],
   "source": [
    "download_files(file_links[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Copy and Rename Files  to be Sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note your mappings may differ due to newly created collections. \n",
    "# use the mapping file for categorizing the sprites (if desired)\n",
    "def copy_rename():\n",
    "    \"\"\"This function takes the downloaded raw sprite files and moves them into another folder.\n",
    "    Then, it renames the files based on an index (lots of duplicates like sword). \n",
    "    Only use this function before sorting into categories for the first time. \n",
    "    Parameters:\n",
    "        None\n",
    "    Returns:\n",
    "        None  \n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs('SpriteFiles2D')\n",
    "        fromDirectory = \"SpriteFiles2DBase\"\n",
    "        toDirectory = \"SpriteFiles2D\"\n",
    "        copy_tree(fromDirectory, toDirectory)\n",
    "\n",
    "        ind = 0; key = {}\n",
    "        for root_folder in os.listdir('SpriteFiles2D'):\n",
    "            os.makedirs('RenamedSprites\\\\'+root_folder)\n",
    "            for r, d, filenames in os.walk('SpriteFiles2D\\\\'+root_folder):\n",
    "                for filename in filenames:\n",
    "                    old_path = os.path.join(r,filename)\n",
    "                    if '.png' in filename:\n",
    "                        new_path = \"RenamedSprites\\\\\"+root_folder+\"\\\\\"+f\"{ind:05d}\"+\".png\"\n",
    "                        os.rename(old_path, new_path)\n",
    "\n",
    "                        key[old_path] = f\"{ind:05d}\"\n",
    "\n",
    "                        ind+=1\n",
    "                    else:\n",
    "                        os.remove(old_path)\n",
    "                        \n",
    "        inv_key =  {v: k for k, v in key.items()}\n",
    "        mappings = {'filepath_id':key, 'id_filepath':inv_key}\n",
    "        \n",
    "        with open('mappings.json', 'w') as outfile:\n",
    "            json.dump(mappings, outfile)\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
